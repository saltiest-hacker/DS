{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "sentinews.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Ur1IRjbSiuqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "\n",
        "# Essencials:\n",
        "\n",
        "import pandas as pd\n",
        "import nltk as nltk\n",
        "import numpy as np\n",
        "import html\n",
        "import re\n",
        "import math\n",
        "import pickle\n",
        "import joblib\n",
        "\n",
        "\n",
        "# Sklearn:\n",
        "\n",
        "import sklearn\n",
        "from sklearn import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "\n",
        "# Tensorflow\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.corpus import subjectivity\n",
        "from nltk.sentiment import SentimentAnalyzer,SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.util import *\n",
        "from nltk import tokenize\n",
        "\n",
        "\n",
        "from IPython.display import clear_output\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Displaying column width to read comment text\n",
        "\n",
        "pd.set_option(\n",
        "    'display.max_colwidth', 0\n",
        ")\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "J8HxAW7ciuqP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "1c5528e2-63da-48c0-a41d-9342618a0554"
      },
      "source": [
        "# Download packages for sentiment analysis\n",
        "\n",
        "nltk.download('subjectivity')\n",
        "nltk.download('vader_lexicon')\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "[nltk_data] Downloading package subjectivity to\n[nltk_data]     /Users/ekaterinaromanovskaya/nltk_data...\n[nltk_data]   Package subjectivity is already up-to-date!\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/ekaterinaromanovskaya/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "WQLq6StsiuqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reading data\n",
        "\n",
        "df = pd.read_csv('hacker_news_sample.csv',nrows=100000)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "K2Kx9_7niuqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data pre-process function\n",
        "\n",
        "def preprocess_df(df):\n",
        "    df = df[df['text'].notna()]\n",
        "    df['neg'], df['neu'], df['pos'], df[\"compound\"], df[\"subjectivity\"] = [np.nan, np.nan,np.nan,np.nan,np.nan]    \n",
        "    return df\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Adding subjectivity column to our data\n",
        "\n",
        "def add_sentiment_subj(df):\n",
        "    sid = SentimentIntensityAnalyzer()\n",
        "    for i, row in df.iterrows():\n",
        "        text = row[\"text\"]\n",
        "        text = html.unescape(text)\n",
        "        text =  re.sub('<[^<]+?>', '', text)\n",
        "        df.at[i,\"text\"] = text\n",
        "        ss = sid.polarity_scores(text)\n",
        "        for k in ss:\n",
        "            df.at[i,k] = ss[k]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "kBzuSPMLiuqV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "51c8709f-0fa6-4070-f5e6-9a2bb1183cd1"
      },
      "source": [
        "# Pre-processing and analysing data\n",
        "\n",
        "df = preprocess_df(df)\n",
        "add_sentiment_subj(df)\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvDxihIuiuqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing data for training\n",
        "\n",
        "X_train, X_test = train_test_split(df)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXjewxuoiuqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I choose comments with non zero compaund \n",
        "\n",
        "scored = X_train.loc[X_train['compound'] != 0]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Making a pipeline\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "        ('vect', CountVectorizer(analyzer='word')),\n",
        "        ('tfidf', TfidfTransformer()),    \n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRZHp2CHiuqc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = pipeline.fit_transform(scored[\"text\"])"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['sklearn_pipeline.pkl']"
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Saving pipeline\n",
        "\n",
        "joblib.dump(pipeline, 'sklearn_pipeline.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4_O744Uiuqq",
        "colab_type": "text"
      },
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1W5VNz3iuqs",
        "colab_type": "code",
        "colab": {},
        "outputId": "02d83a04-4dd6-4427-ba61-56285f181937"
      },
      "source": [
        "# Building a model\n",
        "\n",
        "tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "tree_reg.fit(X, scored[\"compound\"])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "DecisionTreeRegressor(random_state=42)"
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6xt9F-2iuqu",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "scored_test = X_test.loc[X_test['compound'] != 0]\n",
        "X2 = pipeline.transform(scored_test[\"text\"])\n",
        "\n",
        "print(scored_test[\"compound\"].shape)\n",
        "print(X2.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(17270,)\n(17270, 76827)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA_l8KDyiuqw",
        "colab_type": "code",
        "colab": {},
        "outputId": "f59e4b3b-8949-4ca5-def6-4ba0fa147368"
      },
      "source": [
        "# Evaluating a model\n",
        "\n",
        "predictions = tree_reg.predict(X2)\n",
        "\n",
        "tree_mse = mean_squared_error(scored_test[\"compound\"], predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "0.6391272003934664"
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['tree_reg.pkl']"
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Saving a model\n",
        "\n",
        "joblib.dump(tree_reg, 'tree_reg.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['sklearn_pipeline_tree.pkl']"
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Saving relevant pipeline\n",
        "\n",
        "joblib.dump(pipeline, 'sklearn_pipeline_tree.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4AVNJpWiuqz",
        "colab_type": "text"
      },
      "source": [
        "## Keras "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "4pcV79gciuq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Building a neural network\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[X.shape[1]]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "  model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Jh25TiB5iuq1",
        "colab_type": "code",
        "colab": {},
        "outputId": "893af44a-2e04-4e39-d1c5-52a7ea79aa19"
      },
      "source": [
        "model = build_model()\n",
        "model.summary()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 64)                4887488   \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 4,891,713\nTrainable params: 4,891,713\nNon-trainable params: 0\n_________________________________________________________________\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\nTrain on 41558 samples, validate on 10390 samples\nEpoch 1/10\n41536/41558 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0758 - mse: 0.0121\nEpoch 00001: loss improved from inf to 0.01211, saving model to keras/model.hdf5\n41558/41558 [==============================] - 82s 2ms/sample - loss: 0.0121 - mae: 0.0758 - mse: 0.0121 - val_loss: 0.1487 - val_mae: 0.2747 - val_mse: 0.1487\nEpoch 2/10\n41536/41558 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0719 - mse: 0.0108\nEpoch 00002: loss improved from 0.01211 to 0.01083, saving model to keras/model.hdf5\n41558/41558 [==============================] - 95s 2ms/sample - loss: 0.0108 - mae: 0.0719 - mse: 0.0108 - val_loss: 0.1497 - val_mae: 0.2763 - val_mse: 0.1497\nEpoch 3/10\n41536/41558 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0682 - mse: 0.0097\nEpoch 00003: loss improved from 0.01083 to 0.00965, saving model to keras/model.hdf5\n41558/41558 [==============================] - 101s 2ms/sample - loss: 0.0097 - mae: 0.0682 - mse: 0.0097 - val_loss: 0.1491 - val_mae: 0.2750 - val_mse: 0.1491\nEpoch 4/10\n41536/41558 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0646 - mse: 0.0086\nEpoch 00004: loss improved from 0.00965 to 0.00855, saving model to keras/model.hdf5\n41558/41558 [==============================] - 98s 2ms/sample - loss: 0.0086 - mae: 0.0646 - mse: 0.0086 - val_loss: 0.1479 - val_mae: 0.2748 - val_mse: 0.1479\nEpoch 5/10\n41536/41558 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0617 - mse: 0.0078\nEpoch 00005: loss improved from 0.00855 to 0.00777, saving model to keras/model.hdf5\n41558/41558 [==============================] - 100s 2ms/sample - loss: 0.0078 - mae: 0.0617 - mse: 0.0078 - val_loss: 0.1494 - val_mae: 0.2812 - val_mse: 0.1494\nEpoch 6/10\n41536/41558 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0593 - mse: 0.0070\nEpoch 00006: loss improved from 0.00777 to 0.00704, saving model to keras/model.hdf5\n41558/41558 [==============================] - 101s 2ms/sample - loss: 0.0070 - mae: 0.0593 - mse: 0.0070 - val_loss: 0.1474 - val_mae: 0.2798 - val_mse: 0.1474\nEpoch 7/10\n41536/41558 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0567 - mse: 0.0065\nEpoch 00007: loss improved from 0.00704 to 0.00646, saving model to keras/model.hdf5\n41558/41558 [==============================] - 99s 2ms/sample - loss: 0.0065 - mae: 0.0567 - mse: 0.0065 - val_loss: 0.1504 - val_mae: 0.2733 - val_mse: 0.1504\nEpoch 8/10\n41536/41558 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0554 - mse: 0.0061\nEpoch 00008: loss improved from 0.00646 to 0.00610, saving model to keras/model.hdf5\n41558/41558 [==============================] - 99s 2ms/sample - loss: 0.0061 - mae: 0.0554 - mse: 0.0061 - val_loss: 0.1470 - val_mae: 0.2767 - val_mse: 0.1470\nEpoch 9/10\n41536/41558 [============================>.] - ETA: 0s - loss: 0.0057 - mae: 0.0533 - mse: 0.0057\nEpoch 00009: loss improved from 0.00610 to 0.00570, saving model to keras/model.hdf5\n41558/41558 [==============================] - 104s 3ms/sample - loss: 0.0057 - mae: 0.0533 - mse: 0.0057 - val_loss: 0.1492 - val_mae: 0.2750 - val_mse: 0.1492\nEpoch 10/10\n41536/41558 [============================>.] - ETA: 0s - loss: 0.0052 - mae: 0.0515 - mse: 0.0052\nEpoch 00010: loss improved from 0.00570 to 0.00524, saving model to keras/model.hdf5\n41558/41558 [==============================] - 101s 2ms/sample - loss: 0.0052 - mae: 0.0515 - mse: 0.0052 - val_loss: 0.1469 - val_mae: 0.2740 - val_mse: 0.1469\n"
        }
      ],
      "source": [
        "# Checkpoints to save the trained model\n",
        "\n",
        "filepath = \"keras/model.hdf5\"\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor=\"loss\",\n",
        "    verbose=1,\n",
        "    mode=\"min\",\n",
        "    save_best_only=True)\n",
        "history = model.fit(\n",
        "  X, scored[\"compound\"],\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=1, callbacks=[checkpoint_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Ml7H2Q7Ciuq4",
        "colab_type": "code",
        "colab": {},
        "outputId": "d03a010d-b0be-4c49-f382-d2cc95b57981"
      },
      "source": [
        "# Making a prediction on random text\n",
        "\n",
        "def predict_text(text, model = model):\n",
        "    xtemp = pipeline.transform([text])\n",
        "    predictions = model.predict(xtemp)\n",
        "    print(predictions)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "\n",
        "txt = \"Reality is that while China blocks Facebook, Google, etc and smartly props up their own clones, it’s “aghast” at the American protectionism and xenophobic behaviour. How dare the Americans block a Chinese app?! China is not a democracy. It’s not interested in fairness. China is playing the long game. Just like the wars of the past were fought with little toy armies of a few thousand knights and noblemen marching into each other’s countries until someone decided to conscript their whole nation into battle, the West is fighting allowing China to pilfer its technology, wreak the environment, and compete with state backed organisations. Wanna compete with Huawei? Good luck sending in your company noblemen, China is sending their whole nation behind it.\"\n",
        "\n",
        "\n",
        "preds = predict_text(\"Impressive! Personally, I am a few thousand places behind, but still in the top 0.2%. How? I asked and answered a few hundred questions early on, years ago, when SO was new and interesting... Now those answers are old and, like most answers on SO, out of date. Usually when I google something technical and get seemingly the exact right question asked on SO, the answers are no longer correct. Software versions change. And yet I still get a steady trickle of votes, forever increasing the gulf between outdated and no-longer-participating people like me and anyone starting on SO today.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n",
            "[[0.6620629]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "_cWgbwWKiuq6",
        "colab_type": "code",
        "colab": {},
        "outputId": "7b5f90ed-8ba8-4fa1-f8fa-cc308da1370a"
      },
      "source": [
        "predictions = model.predict(X2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn7Ilw53iuq8",
        "colab_type": "code",
        "colab": {},
        "outputId": "d3c41711-fff8-4a49-b997-f5cf910480cb"
      },
      "source": [
        "tree_mse = mean_squared_error(scored_test[\"compound\"], predictions)\n",
        "tree_rmse = np.sqrt(tree_mse)\n",
        "tree_rmse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.39776707368686554"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    }
  ]
}