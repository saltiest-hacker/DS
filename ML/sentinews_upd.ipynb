{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598229406536",
   "display_name": "Python 3.7.7 64-bit ('jupyter': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "import sklearn\n",
    "from sklearn import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer,SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "from nltk import tokenize\n",
    "import numpy as np\n",
    "import html\n",
    "import re\n",
    "pd.set_option(\n",
    "    'display.max_colwidth', 0\n",
    ")\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hacker_news_sample.csv',nrows=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "    df = df[df['text'].notna()]\n",
    "    df['neg'], df['neu'], df['pos'], df[\"compound\"] = [np.nan, np.nan,np.nan,np.nan]    \n",
    "    return df\n",
    "\n",
    "def add_sentiment(df):\n",
    "    df['neg'], df['neu'], df['pos'], df[\"compound\"] = [np.nan, np.nan,np.nan,np.nan]\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    for i, row in df.iterrows():\n",
    "        text = row[\"text\"]\n",
    "        text = html.unescape(text)\n",
    "        text =  re.sub('<[^<]+?>', '', text)\n",
    "        df.at[i,\"text\"] = text\n",
    "        ss = sid.polarity_scores(text)\n",
    "        for k in ss:\n",
    "            df.at[i,k] = ss[k]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             score          time            id        parent  descendants  \\\ncount  1737.000000  8.153000e+04  8.153000e+04  7.979300e+04  1548.000000   \nmean   5.213587     1.387459e+09  7.369586e+06  7.419128e+06  3.410853      \nstd    21.129398    7.622413e+07  4.220612e+06  4.213057e+06  14.535619     \nmin    0.000000     1.172086e+09  3.620000e+02  1.450000e+02 -1.000000      \n25%    1.000000     1.332827e+09  3.760196e+06  3.836577e+06 -1.000000      \n50%    1.000000     1.394251e+09  7.364090e+06  7.439650e+06  0.000000      \n75%    3.000000     1.454520e+09  1.102772e+07  1.106604e+07  2.000000      \nmax    639.000000   1.498466e+09  1.463506e+07  1.463497e+07  368.000000    \n\n       ranking           neg           neu           pos      compound  \ncount  0.0      81530.000000  81530.000000  81530.000000  81530.000000  \nmean  NaN       0.059936      0.825668      0.114299      0.216708      \nstd   NaN       0.082589      0.134709      0.119930      0.529816      \nmin   NaN       0.000000      0.000000      0.000000     -0.999500      \n25%   NaN       0.000000      0.761000      0.018000     -0.077200      \n50%   NaN       0.034000      0.839000      0.094000      0.273200      \n75%   NaN       0.092000      0.912000      0.161000      0.680800      \nmax   NaN       1.000000      1.000000      1.000000      0.999700      ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>score</th>\n      <th>time</th>\n      <th>id</th>\n      <th>parent</th>\n      <th>descendants</th>\n      <th>ranking</th>\n      <th>neg</th>\n      <th>neu</th>\n      <th>pos</th>\n      <th>compound</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1737.000000</td>\n      <td>8.153000e+04</td>\n      <td>8.153000e+04</td>\n      <td>7.979300e+04</td>\n      <td>1548.000000</td>\n      <td>0.0</td>\n      <td>81530.000000</td>\n      <td>81530.000000</td>\n      <td>81530.000000</td>\n      <td>81530.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>5.213587</td>\n      <td>1.387459e+09</td>\n      <td>7.369586e+06</td>\n      <td>7.419128e+06</td>\n      <td>3.410853</td>\n      <td>NaN</td>\n      <td>0.059936</td>\n      <td>0.825668</td>\n      <td>0.114299</td>\n      <td>0.216708</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>21.129398</td>\n      <td>7.622413e+07</td>\n      <td>4.220612e+06</td>\n      <td>4.213057e+06</td>\n      <td>14.535619</td>\n      <td>NaN</td>\n      <td>0.082589</td>\n      <td>0.134709</td>\n      <td>0.119930</td>\n      <td>0.529816</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>1.172086e+09</td>\n      <td>3.620000e+02</td>\n      <td>1.450000e+02</td>\n      <td>-1.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.999500</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>1.332827e+09</td>\n      <td>3.760196e+06</td>\n      <td>3.836577e+06</td>\n      <td>-1.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.761000</td>\n      <td>0.018000</td>\n      <td>-0.077200</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.000000</td>\n      <td>1.394251e+09</td>\n      <td>7.364090e+06</td>\n      <td>7.439650e+06</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.034000</td>\n      <td>0.839000</td>\n      <td>0.094000</td>\n      <td>0.273200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>3.000000</td>\n      <td>1.454520e+09</td>\n      <td>1.102772e+07</td>\n      <td>1.106604e+07</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>0.092000</td>\n      <td>0.912000</td>\n      <td>0.161000</td>\n      <td>0.680800</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>639.000000</td>\n      <td>1.498466e+09</td>\n      <td>1.463506e+07</td>\n      <td>1.463497e+07</td>\n      <td>368.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.999700</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 164
    }
   ],
   "source": [
    "df = preprocess_df(df)\n",
    "add_sentiment(df)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored = X_train.loc[X_train['compound'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pipeline.fit_transform(scored[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('vect', CountVectorizer(analyzer='word')),\n",
    "        ('tfidf', TfidfTransformer()),    \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n                      max_features=None, max_leaf_nodes=None,\n                      min_impurity_decrease=0.0, min_impurity_split=None,\n                      min_samples_leaf=1, min_samples_split=2,\n                      min_weight_fraction_leaf=0.0, presort='deprecated',\n                      random_state=42, splitter='best')"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(X, scored[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_test = X_test.loc[X_test['compound'] != 0]\n",
    "X2 = pipeline.transform(scored_test[\"text\"])\n",
    "print(scored_test[\"compound\"].shape)\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.6365505601380854"
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "predictions = tree_reg.predict(X2)\n",
    "\n",
    "tree_mse = mean_squared_error(scored_test[\"compound\"], predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "def build_model():\n",
    "  model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=[X.shape[1]]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 64)                4916992   \n_________________________________________________________________\ndense_4 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 65        \n=================================================================\nTotal params: 4,921,217\nTrainable params: 4,921,217\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\nTrain on 41576 samples, validate on 10395 samples\nEpoch 1/10\n41576/41576 [==============================] - 102s 2ms/sample - loss: 0.1676 - mae: 0.3143 - mse: 0.1676 - val_loss: 0.1464 - val_mae: 0.2798 - val_mse: 0.1464\nEpoch 2/10\n41576/41576 [==============================] - 110s 3ms/sample - loss: 0.1047 - mae: 0.2321 - mse: 0.1047 - val_loss: 0.1346 - val_mae: 0.2717 - val_mse: 0.1346\nEpoch 3/10\n41576/41576 [==============================] - 105s 3ms/sample - loss: 0.0793 - mae: 0.1950 - mse: 0.0793 - val_loss: 0.1419 - val_mae: 0.2650 - val_mse: 0.1419\nEpoch 4/10\n41576/41576 [==============================] - 111s 3ms/sample - loss: 0.0593 - mae: 0.1650 - mse: 0.0593 - val_loss: 0.1399 - val_mae: 0.2785 - val_mse: 0.1399\nEpoch 5/10\n41576/41576 [==============================] - 105s 3ms/sample - loss: 0.0442 - mae: 0.1402 - mse: 0.0442 - val_loss: 0.1430 - val_mae: 0.2678 - val_mse: 0.1430\nEpoch 6/10\n41576/41576 [==============================] - 105s 3ms/sample - loss: 0.0335 - mae: 0.1217 - mse: 0.0335 - val_loss: 0.1464 - val_mae: 0.2794 - val_mse: 0.1464\nEpoch 7/10\n41576/41576 [==============================] - 101s 2ms/sample - loss: 0.0259 - mae: 0.1077 - mse: 0.0259 - val_loss: 0.1449 - val_mae: 0.2712 - val_mse: 0.1449\nEpoch 8/10\n41576/41576 [==============================] - 106s 3ms/sample - loss: 0.0208 - mae: 0.0973 - mse: 0.0208 - val_loss: 0.1442 - val_mae: 0.2729 - val_mse: 0.1442\nEpoch 9/10\n41576/41576 [==============================] - 98s 2ms/sample - loss: 0.0172 - mae: 0.0891 - mse: 0.0172 - val_loss: 0.1455 - val_mae: 0.2706 - val_mse: 0.1455\nEpoch 10/10\n41576/41576 [==============================] - 97s 2ms/sample - loss: 0.0146 - mae: 0.0829 - mse: 0.0146 - val_loss: 0.1484 - val_mae: 0.2752 - val_mse: 0.1484\n"
    }
   ],
   "source": [
    "history = model.fit(\n",
    "  X, scored[\"compound\"],\n",
    "  epochs=EPOCHS, validation_split = 0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n[[0.6620629]]\n"
    }
   ],
   "source": [
    "def predict_text(text, model = model):\n",
    "    xtemp = pipeline.transform([text])\n",
    "    predictions = model.predict(xtemp)\n",
    "    print(predictions)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "txt = \"Reality is that while China blocks Facebook, Google, etc and smartly props up their own clones, it’s “aghast” at the American protectionism and xenophobic behaviour. How dare the Americans block a Chinese app?! China is not a democracy. It’s not interested in fairness. China is playing the long game. Just like the wars of the past were fought with little toy armies of a few thousand knights and noblemen marching into each other’s countries until someone decided to conscript their whole nation into battle, the West is fighting allowing China to pilfer its technology, wreak the environment, and compete with state backed organisations. Wanna compete with Huawei? Good luck sending in your company noblemen, China is sending their whole nation behind it.\"\n",
    "\n",
    "\n",
    "preds = predict_text(\"Impressive! Personally, I am a few thousand places behind, but still in the top 0.2%. How? I asked and answered a few hundred questions early on, years ago, when SO was new and interesting... Now those answers are old and, like most answers on SO, out of date. Usually when I google something technical and get seemingly the exact right question asked on SO, the answers are no longer correct. Software versions change. And yet I still get a steady trickle of votes, forever increasing the gulf between outdated and no-longer-participating people like me and anyone starting on SO today.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'scipy.sparse.csr.csr_matrix'>, <class 'NoneType'>\n"
    }
   ],
   "source": [
    "predictions = model.predict(X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.39776707368686554"
     },
     "metadata": {},
     "execution_count": 161
    }
   ],
   "source": [
    "tree_mse = mean_squared_error(scored_test[\"compound\"], predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  }
 ]
}